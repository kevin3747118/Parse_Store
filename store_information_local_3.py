#-*- coding: utf-8 -*-
from DB_CONNECTION import connection
from bs4 import BeautifulSoup
import urllib.request, random, time, logging


class scrapy_need():

    def __init__(self):

        self.__az = connection.db('AZURE')
        __FORMAT = '%(asctime)s %(message)s'
        logging.basicConfig(format=__FORMAT, level=logging.INFO, filename='store.log')
        # logging.basicConfig(format=__FORMAT, level=logging.DEBUG)
        self.logger = logging.getLogger('SINGLE_STORE')

    def get_page(self, url, parameters=None):
        if parameters:
            encode_parameters = urllib.parse.urlencode(parameters).encode('utf-8')
        else:
            encode_parameters = None
        time.sleep(0.33)
        request = urllib.request.Request(url)

        ####éš¨æ©ŸheaderæŒ‘é¸####
        foo = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36',
            'Mozilla/5.0 (compatible, MSIE 11, Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko',
            'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1'
            'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_7; da-dk) AppleWebKit/533.21.1 (KHTML, like Gecko) Version/5.0.5 Safari/533.21.1'
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'
            'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2722.0 Safari/537.36'
            'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36'
        ]
        headers = str(random.choice(foo))
        ####éš¨æ©ŸheaderæŒ‘é¸####

        request.add_header('User-Agent', headers)
        time.sleep(0.42)
        response = urllib.request.urlopen(request, data=encode_parameters, timeout=180)
        html = BeautifulSoup(response.read().decode('utf-8'), 'lxml')
        response.close()

        return html

    def parse_store(self, store_data):

        # self.logger.info(store_data)
        # def address_remove(store_addr):
        #     result = [i for i in store_addr if not i.isdigit() and i not in 'å··è™Ÿå¼„æ¨“ä¹‹-ABCèˆ‡()']
        #     address_remove_string = ''.join(result)
        #     # logging.debug(address_remove_string)
        #     return address_remove_string

        def return_store_html(store_data):

            if len(store_data) == 6:
                #ç‰¹ç´„å•†åº—åç¨±, åœ°å€, ç¸£å¸‚åç¨±, åœ°å€åç¨±
                terms1 = urllib.parse.quote(store_data[1] + ' ' + store_data[2])
                terms2 = urllib.parse.quote(store_data[1] + ' ' + store_data[3] + ' ' + store_data[5])
            else:
                #ç‰¹ç´„å•†åº—åç¨±, åˆ†åº—åç¨±, åœ°å€, ç¸£å¸‚åç¨±, åœ°å€åç¨±
                terms1 = urllib.parse.quote(store_data[1] + ' ' + store_data[3] + ' ' + store_data[4])
                terms2 = urllib.parse.quote(store_data[1] + ' ' + store_data[3] + ' ' + store_data[2])

            url1 = 'https://www.google.com.tw/search?&q=' + terms1 + '&oq=' + terms1
            url2 = 'https://www.google.com.tw/search?&q=' + terms2 + '&oq=' + terms2

            soup1 = self.get_page(url1)
            soup2 = self.get_page(url2)

            # return url1, url2
            return soup1, soup2

        ###kernel of program###
        def verify_store_info(store_data):

            self.logger.debug(store_data)
            store_data = [i.replace('é›»è©±ï¼š', '') for i in store_data]
            if len(store_data) == 5:
                if store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[1]) > 8:
                    address = store_data[0]
                    phone = store_data[1].replace(' ', '-')
                elif store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[2]) > 8:
                    address = store_data[0]
                    phone = store_data[2].replace(' ', '-')
                elif store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[3]) > 8:
                    address = store_data[0]
                    phone = store_data[3].replace(' ', '-')
                elif store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[4]) > 8:
                    address = store_data[0]
                    phone = store_data[4].replace(' ', '-')
                elif store_data[0][0] != '0' and (sum(i.isdigit() for i in store_data[1]) < 8 or
                                                  sum(i.isdigit() for i in store_data[2]) < 8 or
                                                  sum(i.isdigit() for i in store_data[3]) < 8 or
                                                  sum(i.isdigit() for i in store_data[4]) < 8):
                    address = store_data[0]
                    phone = ''
                else:
                    address = ''
                    phone = ''
            elif len(store_data) == 4:
                if store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[1]) > 8:
                    address = store_data[0]
                    phone = store_data[1].replace(' ', '-')
                elif store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[2]) > 8:
                    address = store_data[0]
                    phone = store_data[2].replace(' ', '-')
                elif store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[3]) > 8:
                    address = store_data[0]
                    phone = store_data[3].replace(' ', '-')
                elif store_data[0][0] != '0' and (sum(i.isdigit() for i in store_data[1]) < 8 or
                                                  sum(i.isdigit() for i in store_data[2]) < 8 or
                                                  sum(i.isdigit() for i in store_data[3]) < 8):
                    address = store_data[0]
                    phone = ''
                else:
                    address = ''
                    phone = ''
            elif len(store_data) == 3:
                if store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[1]) > 8:
                    address = store_data[0]
                    phone = store_data[1].replace(' ', '-')
                elif store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[2]) > 8:
                    address = store_data[0]
                    phone = store_data[2].replace(' ', '-')
                elif store_data[0][0] != '0' and (sum(i.isdigit() for i in store_data[2]) < 8 and
                                                          sum(i.isdigit() for i in store_data[1]) < 8):
                    address = store_data[0]
                    phone = ''
                else:
                    address = ''
                    phone = ''
            elif len(store_data) == 2:
                if store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[1]) > 8:
                    address = store_data[0]
                    phone = store_data[1].replace(' ', '-')
                elif store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[1]) < 8:
                    address = store_data[0]
                    phone = ''
                else:
                    address = ''
                    phone = ''
            elif len(store_data) == 1:
                if store_data[0][0] != '0' and sum(i.isdigit() for i in store_data[0]) < 8:
                    address = store_data[0]
                    phone = ''
                elif sum(i.isdigit() for i in store_data[0]) > 8:
                    address = ''
                    phone = store_data[0].replace(' ', '-')
                else:
                    address = ''
                    phone = ''
            else:
                address = ''
                phone = ''

            # self.logger.debug((phone, address))
            return [phone, address]
        ###kernel of program###

        def verify_parking(store_data):
            parking_logo = 'ğŸš§'
            if store_data[1].find(parking_logo) == -1:
                store_data.append('ä¸æä¾›')
            else:
                store_data[1] = store_data[1].replace('ğŸš§ é™„å…è²»åœè»Šå ´', '')
                store_data.append('æä¾›')

            return store_data

        def info(store_data):
            if len(store_data) == 6:
            # if len(store_data) == 6:
                self.logger.info('start parsing multiple stores...')
                # self.logger.debug(('info : 6', store_data))
            else:
                self.logger.info('start parsing single stores...')
                # self.logger.debug(('info : else', store_data))

        start_time = time.strftime("%Y%m%d %H:%M", time.gmtime())
        self.logger.info(start_time)
        info(store_data)

        count = 0
        for i in store_data:
#            self.logger.info(i)

            count += 1
            if count % 1200 == 0:
                time.sleep(120)

            html_result = return_store_html(i)
            html_result1 = html_result[0]
            html_result2 = html_result[1]

            store_infos = list()
            week_infos_dict = dict()
            PSD_NUM = i[0]
            date = time.strftime("%Y%m%d", time.gmtime())
            weeks = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']

            ###html_result1###
            if html_result1.find_all('span', class_="_Xbe"):
                ###get address & phone###
                for store_information in html_result1.find_all('span', {'class': '_Xbe'}):
                    store_infos.append(store_information.text)

                try:
                    db_store_infos = verify_store_info(store_infos)
                except Exception as err:
                    self.logger.critical((err, i))
                ###get address & phone###

                ###get store status###
                if html_result1.find_all('span', class_="_Gtg"):
                    for status_tag in html_result1.find_all('span', class_="_Gtg"):
                        db_store_infos.append(status_tag.find_next('span').text)
                else:
                    db_store_infos.append('æ­£å¸¸ç‡Ÿæ¥­')
                ###get store status###

                ###provide parking place####
                db_store_infos = verify_parking(db_store_infos)
                ###provide parking place####

                ###critical message###
                if len(db_store_infos) != 4:
                    self.logger.critical(('160',i))
                ###critical message###

                ###get store open time###
                if html_result1.find_all('td', class_="_X0c"):
                    for week_tag in html_result1.find_all('td', class_="_X0c"):
                        if len(week_tag.text) != 3:
                            week_infos_dict[week_tag.text[:3]] = week_tag.find_next('td').text.replace('ç‡Ÿæ¥­æ™‚é–“å¯èƒ½ä¸åŒ', '')
                        else:
                            week_infos_dict[week_tag.text] = week_tag.find_next('td').text.replace('ç‡Ÿæ¥­æ™‚é–“å¯èƒ½ä¸åŒ', '')
                else:
                    for week_tag in weeks:
                        week_infos_dict[week_tag] = ''
                ###get store open time###

                ###convert db_store_infos and week_infos_dict to tuple###
                result = tuple(db_store_infos + [week_infos_dict['æ˜ŸæœŸä¸€'], week_infos_dict['æ˜ŸæœŸäºŒ'],
                                                 week_infos_dict['æ˜ŸæœŸä¸‰'], week_infos_dict['æ˜ŸæœŸå››'],
                                                 week_infos_dict['æ˜ŸæœŸäº”'], week_infos_dict['æ˜ŸæœŸå…­'],
                                                 week_infos_dict['æ˜ŸæœŸæ—¥'], date, PSD_NUM])
                ###convert db_store_infos and week_infos_dict to tuple###
                sql_stat = ("""UPDATE [dbo].[store_information_local_3]
                                SET [googleé›»è©±] = %s,[googleåœ°å€] = %s,[ç‡Ÿæ¥­ç‹€æ…‹] = %s,[åœè»Šå ´] = %s
                                ,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸä¸€] = %s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸäºŒ] = %s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸä¸‰] = %s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸå››] = %s
                                ,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸäº”] =%s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸå…­] = %s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸæ—¥] = %s, [æ›´æ–°æ—¥æœŸ] = %s
                                WHERE [ITç·¨è™Ÿ] = %s""")

                if len(result) != 13:
                    self.logger.critical(result)
                try:
                    # self.logger.debug(result)
                    self._scrapy_need__az.do_query(sql_stat, result)
                    self._scrapy_need__az.do_commit()
                # except self._scrapy_need__az.error_handle().DatabaseError as err:
                except Exception as err:
                    self.logger.critical((err, result))

            ###html_result1###

            ###html_result2###
            elif html_result2.find_all('span', class_="_Xbe"):
                ###get address & phone###
                for store_information in html_result2.find_all('span', {'class': '_Xbe'}):
                    store_infos.append(store_information.text)

                try:
                    db_store_infos = verify_store_info(store_infos)
                except Exception as err:
                    self.logger.critical((err, i))
                ###get address & phone###

                ###get store status###
                if html_result2.find_all('span', class_="_Gtg"):
                    for status_tag in html_result2.find_all('span', class_="_Gtg"):
                        db_store_infos.append(status_tag.find_next('span').text)
                else:
                    db_store_infos.append('æ­£å¸¸ç‡Ÿæ¥­')
                ###get store status###

                ###provide parking place####
                db_store_infos = verify_parking(db_store_infos)
                self.logger.debug(db_store_infos)
                ###provide parking place####

                ###critical message###
                if len(db_store_infos) != 4:
                    self.logger.critical(i)
                ###critical message###

                ###get store open time###
                if html_result2.find_all('td', class_="_X0c"):
                    for week_tag in html_result2.find_all('td', class_="_X0c"):
                        if len(week_tag.text) != 3:
                            week_infos_dict[week_tag.text[:3]] = week_tag.find_next('td').text.replace('ç‡Ÿæ¥­æ™‚é–“å¯èƒ½ä¸åŒ', '')
                        else:
                            week_infos_dict[week_tag.text] = week_tag.find_next('td').text.replace('ç‡Ÿæ¥­æ™‚é–“å¯èƒ½ä¸åŒ', '')
                else:
                    for week_tag in weeks:
                        week_infos_dict[week_tag] = ''
                ###get store open time###

                # logging.debug(week_infos_dict)

                ###convert db_store_infos and week_infos_dict to tuple###
                result = tuple(db_store_infos + [week_infos_dict['æ˜ŸæœŸä¸€'], week_infos_dict['æ˜ŸæœŸäºŒ'],
                                                 week_infos_dict['æ˜ŸæœŸä¸‰'], week_infos_dict['æ˜ŸæœŸå››'],
                                                 week_infos_dict['æ˜ŸæœŸäº”'], week_infos_dict['æ˜ŸæœŸå…­'],
                                                 week_infos_dict['æ˜ŸæœŸæ—¥'], date, PSD_NUM])
                ###convert db_store_infos and week_infos_dict to tuple###

                sql_stat = ("""UPDATE [dbo].[store_information_local_3]
                                SET [googleé›»è©±] = %s,[googleåœ°å€] = %s,[ç‡Ÿæ¥­ç‹€æ…‹] = %s,[åœè»Šå ´] = %s
                                ,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸä¸€] = %s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸäºŒ] = %s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸä¸‰] = %s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸå››] = %s
                                ,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸäº”] =%s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸå…­] = %s,[ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸæ—¥] = %s, [æ›´æ–°æ—¥æœŸ] = %s
                                WHERE [ITç·¨è™Ÿ] = %s""")
                # self.logger.debug(result)
                if len(result) != 13:
                    self.logger.critical(result)
                try:
                    # self.logger.debug(result)
                    self._scrapy_need__az.do_query(sql_stat, result)
                    self._scrapy_need__az.do_commit()
                # except self._scrapy_need__az.error_handle().DatabaseError as err:
                except Exception as err:
                    self.logger.critical((err, result))

            else:
                result = (date, PSD_NUM)
                sql_stat = ("""update [dbo].[store_information_local_3]
                                set googleé›»è©± = 'æŸ¥ç„¡googleè³‡æ–™', [googleåœ°å€] = 'æŸ¥ç„¡googleè³‡æ–™'
                                ,ç‡Ÿæ¥­ç‹€æ…‹ = '', åœè»Šå ´ = '', ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸä¸€ = '', ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸäºŒ = ''
                                ,ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸä¸‰ = '', ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸå›› = '', ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸäº” = ''
                                ,ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸå…­ = '', ç‡Ÿæ¥­æ™‚é–“æ˜ŸæœŸæ—¥ = '', [æ›´æ–°æ—¥æœŸ] = %s
                                where [ITç·¨è™Ÿ] = %s""")
                try:
                    self._scrapy_need__az.do_query(sql_stat, result)
                    self._scrapy_need__az.do_commit()
                except Exception as err:
                    self.logger.critical((err, i))

        end_time = time.strftime("%Y%m%d %H:%M", time.gmtime())
        self.logger.info(end_time)

class get_store_data(scrapy_need):

    def __init__(self):
        scrapy_need.__init__(self)

    def __get_store_area(self):

        sql_stat = ("""select distinct(å€) from [dbo].[store_information_local_3]
                        where googleé›»è©± is null""")
        result = self._scrapy_need__az.do_query(sql_stat)

        return result

    def get_single_store(self):

        result = list()
        __single_area = self.__get_store_area()
        # self.logger.debug(__single_area)
        for i in range(len(__single_area)):
            __single_area_parameter = str(__single_area[i][0])
            # self.logger.debug(__single_area_parameter)
            sql_stat = ("""SELECT ITç·¨è™Ÿ, åº—å, [åœ°å€(ä¸å«å¸‚å€)], å¸‚, å€
                           from dbo.store_information_local_3
                           where åº—å in (select åº—å FROM dbo.store_information_local_3
                           group by åº—å having count(*) <= 1 )
                           and å€ = %s and åˆ†åº— = '' and googleé›»è©± is null""")
            data = self._scrapy_need__az.do_query(sql_stat, __single_area_parameter)
            result.extend(data)
        # self.logger.debug(result)
        return result

    def __get_store_area_multi(self):

        sql_stat = ("""select distinct(å€) from [dbo].[store_information_local_3]
                       where googleé›»è©± is null or googleé›»è©± = 'æŸ¥ç„¡googleè³‡æ–™' """)
        result = self._scrapy_need__az.do_query(sql_stat)

        return result

    def get_multiple_store(self):

        result = list()
        __multiple_area = self.__get_store_area_multi()
        # self.logger.debug(__multiple_area)
        for i in range(len(__multiple_area)):
            __multiple_area_parameter = str(__multiple_area[i][0])
            sql_stat = ("""SELECT ITç·¨è™Ÿ, åº—å, åˆ†åº—, [åœ°å€(ä¸å«å¸‚å€)], å¸‚, å€
                           from dbo.store_information_local_3
                           where å€ = %s and googleé›»è©± is null """)
            data = self._scrapy_need__az.do_query(sql_stat, __multiple_area_parameter)
            result.extend(data)
        # self.logger.debug(result)
        return result



if __name__ == '__main__':

    # test_data = [(123, 'åŒ—æŠ•äºå¤ªæº«æ³‰ç”Ÿæ´»é¤¨', 'æº«æ³‰è·¯éŠ€å…‰å··21-2è™Ÿ', 'å°åŒ—å¸‚', 'åŒ—æŠ•å€'),
    #              (456, 'å¥½æ—¥å­å’–å•¡ MD_cafe', 'ç«‹è¾²è¡—äºŒæ®µ293è™Ÿ', 'å°åŒ—å¸‚', 'åŒ—æŠ•å€')]
    stores = get_store_data()
    single_data = stores.get_single_store()
    stores.parse_store(single_data)
    multi_data = stores.get_multiple_store()
    stores.parse_store(multi_data)
    print('finish')
    ###verify area###
    # for i in data:
    #     logging.debug((i[0][5],len(i)))
    ###verify area###w
